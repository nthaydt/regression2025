---
title: "Intro To Regression"
author: "Haydt, Donahue, and Worm"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries

```{r libraries}
library(lme4)
library(AICcmodavg)
library(GGally)
library(sjPlot)
```

Data Sets:
Shrike Habitat Data - 
Chesapeake and Ohio Canal Turtle Data - 

## Bring in Data Sets
```{r}
turtle_data <- read.csv("data/CO-turtles.csv")
shrike_data <- read.csv("data/shrike_habitat_data.csv")
```

## Linear Models
```{r}
# Does turtle species or carapace length impact individual mass?
m1 <- lm(data = turtle_data, mass ~ species) # same as an anova
m2 <- lm(data = turtle_data, mass ~ carapace)
m3 <- lm(data = turtle_data, mass ~ species + carapace) # examine as independent terms
m4 <- lm(data = turtle_data, mass ~ species*carapace) # examine species and carapace as both interaction terms and independent terms
m5 <- lm(data = turtle_data, mass ~ species:carapace) # just looking at interactions

summary(m1)
summary(m2)
summary(m3)
summary(m4)
summary(m5)
```

## Generalized Linear Models
```{r}

```

### MIXED MODELS
Fixed vs. random effects:


## Linear Mixed Models
```{r}
# Does carapace length impact individual mass?
m1 <- lmer(data = turtle_data, mass ~ carapace + (1|species))
summary(m1)

library(lmerTest)
m2 <- lmerTest::lmer(data = turtle_data, mass ~ carapace + (1|species))
summary(m2)
```

## Generalized Linear Mixed Models
```{r}

#Rescale Wire Length since we have much larger values (i.e. 1000 m) when compared to other variables
rescale<-function(x) (x-min(x)) / (max(x) - min(x)) * 100
Wire100scale<-rescale(Habitat$Wire100)




##____________________________________________________________________________________________________________

## Site-Level Characteristics

##________________________________________________________________________________________________________________

# Check for correlation of variables to be included in models
# (Values of r>0.7 typically considered highly correlated, decide which to remove)

cor(Habitat[, c("PerchH5", "Crops11", "Water11")], use = "complete.obs")

ggpairs(Habitat, columns = c("PerchH5", "Crops11", "Water11"))

# Build full model with all variables of interest

site_full<- glmer(Use ~ PerchH5 + Crops11 + Water11 + 
                    (1|PointID) + (1|BirdID), family = binomial, data = Habitat)

# Singularity error may result if random effect explains too little variance,
# But random errors are important to include here to pair used/random points and account for psuedo-replication

# Run models with all possible combinations of predictor variables and null with dredge function

options(na.action = "na.fail") #Ensure each model is run with the same dataset and no rows are excluded because of NA values
model_set1 <- dredge(site_full)

# Analyze models by comparing AICc values
# Models in table with deltaAICc (delta) values < 2 considered equivalent
print(model_set1)

#Build top models (delta AICc<2) from dredge table output --> print(model_set1)

site_top1<- glmer(Use ~ PerchH5 + Water11 + 
                 (1|PointID), family = binomial, data = Habitat)

site_top2<- glmer(Use ~ Crops11 + PerchH5 + Water11 + 
                 (1|PointID) + (1|BirdID), family = binomial, nAGQ =1, data = Habitat)

# Evaluate confidence intervals to evaluate which parameters may be important in explaining response variable
# Variable is important if its 85% confidence interval does not overlap (see Arnold 2010)

confint(site_top1,level=0.85, method="Wald")
confint(site_top2,level=0.85, method="Wald")

# Use summary function to get beta estimates for each important predictor variable
#Beta > 0 --> positive correlation, Beta < 0 --> negative correlation

summary(site_top1)
summary(site_top2)

##_________________Plots_______________________##

#Make plot with predicted values to visualize model correlation trends

plot_model(site_top1, type = "pred", terms = "Water11")
plot_model(site_top1, type = "pred", terms="PerchH5 [all]") #[all ensures smooth plot]


# Make boxplot with predicted values to visualize model correlation trends for binary variables

#Get predicted probabilities from the model (fine_top1)
predicted_values <- predict(site_top1, type = "response")

# Create a new data frame that includes the predicted and actual values for Water11
prediction_data <- data.frame(
  Water11 = Habitat$Water11,
  Predicted = predicted_values
)

# Create a boxplot with ggplot2
ggplot(prediction_data, aes(x = factor(Water11), y = Predicted)) +
  geom_boxplot(fill = "lightblue", color = "blue") +  # Boxplot with color customization
  geom_jitter(width = 0.2, alpha = 0.5) +             # Add jittered points for better visualization
  labs(title = "Predicted Probabilities by Water11", 
       x = "Water11", y = "Predicted Probability") +
  theme_minimal()




##__________________________________________________________________________________________________________

## Fine-scale Level Characteristics

##____________________________________________________________________________________________________________


# Check for correlation of variables to be included in models
# (Values of r>0.7 typically considered highly correlated, decide which to remove)

cor(Habitat[, c("Ditches100", "GrassWavg100", "GrassHavg100", "Wire100")], use = "complete.obs")

ggpairs(Habitat, columns = c("Ditches100", "GrassWavg100", "GrassHavg100", "Wire100"))

# Build full model with all variables of interest

fine_full<- glmer(Use ~ Ditches100 + GrassWavg100 + GrassHavg100 + Wire100scale + 
                    (1|PointID) + (1|BirdID), family = binomial, nAGQ =1, data = Habitat)

# Run models with all possible combinations of predictor variables and null with dredge function

options(na.action = "na.fail") #Ensure each model is run with the same dataset and no rows are excluded because of NA values

model_set2 <- dredge(fine_full)

# Analyze models by comparing AICc values
# Models in table with deltaAICc (delta) values < 2 considered equivalent
print(model_set2)

# Build top models (delta AICc<2) from dredge table output --> print(model_set1)

fine_top1<- glmer(Use ~ GrassHavg100 +
                    (1|PointID) + (1|BirdID), family = binomial, data = Habitat)

fine_top2<- glmer(Use ~ Ditches100 + GrassHavg100 + Wire100scale +
                    (1|PointID) + (1|BirdID), family = binomial, nAGQ =1, data = Habitat)

fine_top3<- glmer(Use ~ GrassWavg100 + GrassHavg100 + Wire100scale +
                    (1|PointID) + (1|BirdID), family = binomial, nAGQ =1, data = Habitat)

# Evaluate confidence intervals to evaluate which parameters may be important in explaining response variable
# Variable is important if its 85% confidence interval does not overlap (see Arnold 2010)

confint(fine_top1,level=0.85, method="Wald")
confint(fine_top2,level=0.85, method="Wald")
confint(fine_top3,level=0.85, method="Wald")

# Use summary function to get beta estimates for each important predictor variable
# Beta > 0 --> positive correlation, Beta < 0 --> negative correlation

summary(fine_top1)
summary(fine_top2)
summary(fine_top3)

##____________________Plots_____________________##

# Model plots to visualize correlation trends

plot_model(fine_top1, type = "pred", terms = "GrassHavg100 [all]")
plot_model(fine_top2, type = "pred", terms="Wire100scale")


##_______________________________________________________________________________________________________

## Broad-scale Level Characteristics

##_________________________________________________________________________________________________________



# Check for correlation of variables to be included in models
# (Values of r>0.7 typically considered highly correlated, decide which to remove)

cor(Habitat[, c("Cotton500", "Rice500", "Soy500", "Develop500", "Forest500")], use = "complete.obs")

ggpairs(Habitat, columns = c("Cotton500", "Rice500", "Soy500", "Develop500", "Forest500"))

#Build full model with all variables of interest

broad_full<- glmer(Use ~ Cotton500 + Rice500 + Soy500 + Develop500 + Forest500 +
                    (1|PointID) + (1|BirdID), family = binomial, nAGQ =1, data = Habitat)

# Run models with all possible combinations of predictor variables and null with dredge function

options(na.action = "na.fail") #Ensure each model is run with the same dataset and no rows are excluded because of NA values

model_set3 <- dredge(broad_full)

# Analyze models by comparing AICc values
# Models in table with deltaAICc (delta) values < 2 considered equivalent
print(model_set3)

# Build top models (delta AICc<2) from dredge table output --> print(model_set1)

broad_top1<- glmer(Use ~ Develop500 +
                    (1|PointID) + (1|BirdID), family = binomial, data = Habitat)

broad_top2<- glmer(Use ~ Develop500 + Soy500 +
                    (1|PointID) + (1|BirdID), family = binomial, nAGQ =1, data = Habitat)

broad_top3<- glmer(Use ~ Develop500 + Forest500 +
                    (1|PointID) + (1|BirdID), family = binomial, nAGQ =1, data = Habitat)

broad_top4<- glmer(Use ~ Develop500 + Rice500 +
                     (1|PointID) + (1|BirdID), family = binomial, nAGQ =1, data = Habitat)

broad_top5<- glmer(Use ~ Develop500 + Cotton500 +
                     (1|PointID) + (1|BirdID), family = binomial, nAGQ =1, data = Habitat)


# Evaluate confidence intervals to evaluate which parameters may be important in explaining response variable
# Variable is important if its 85% confidence interval does not overlap (see Arnold 2010)

confint(broad_top1,level=0.85, method="Wald")
confint(broad_top2,level=0.85, method="Wald")
confint(broad_top3,level=0.85, method="Wald")
confint(broad_top4,level=0.85, method="Wald")
confint(broad_top5,level=0.85, method="Wald")

# Use summary function to get beta estimates for each important predictor variable
# Beta > 0 --> positive correlation, Beta < 0 --> negative correlation

summary(broad_top1)


##____________________Plots_____________________##

#Model plots to visualize correlation trends

plot_model(broad_top1, type = "pred", terms = "Develop500 [all]")

##______________________________________________________________________________________________________________





```

## Making Tables with Regression Outputs
```{r}

```

## Viewing Effects (Including interaction effects)
```{r}

```


